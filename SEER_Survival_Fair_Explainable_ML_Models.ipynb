{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b26333",
   "metadata": {},
   "source": [
    "# Cancer Types and Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c12215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install neccessary packages \n",
    "!pip install aif360==0.5.0\n",
    "!pip install fairlearn==0.10.0\n",
    "!pip install lime==0.2.0.1\n",
    "!pip install matplotlib==3.7.2\n",
    "!pip install numpy==1.24.3\n",
    "!pip install pandas==2.0.3\n",
    "!pip install plotly==5.9.0\n",
    "!pip install seaborn==0.12.2\n",
    "!pip install shap==0.44.1\n",
    "!pip install sklearn==1.3.0\n",
    "!pip install xgboost==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load dataset from SHRS_smallDS.xlsx\n",
    "df = pd.read_csv('Seer_Old datasets/bladder.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dceaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_type_df = df[['age',\n",
    "                    'gender_code',\n",
    "                    ' behaviour_code',\n",
    "                    'cs_extension_code',\n",
    "                    'grade_code10',\n",
    "                    'histologic_type_code',\n",
    "                    'cs_lymph_nodes_code',\n",
    "                    'marital_status_code',\n",
    "                    'cs_mets_at_dx_code',\n",
    "                    'primary_site_code7',\n",
    "                    'race_code',\n",
    "                    ' radiation_code',\n",
    "                    ' number_of_nodes_examined',\n",
    "                    ' regional_positive_nodes ',\n",
    "                    'number_of_primaries',\n",
    "                    ' site_specific_surgery_code',\n",
    "                    'stage_of_cancer_code',\n",
    "                    'cs_tumor_size',\n",
    "                    'survived_code ']]\n",
    "\n",
    "cancer_type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "cancer_type_df = cancer_type_df.dropna()\n",
    "\n",
    "cancer_type_df['survived_code '] = cancer_type_df['survived_code '].map({'yes': 1, 'no': 0})\n",
    "cancer_type_df['primary_site_code7'] = cancer_type_df['primary_site_code7'].str[1:]\n",
    "cancer_type_df['primary_site_code7'] = pd.to_numeric(cancer_type_df['primary_site_code7'], errors='raise')\n",
    "\n",
    "cancer_type_df['stage_of_cancer_code'] = cancer_type_df['stage_of_cancer_code'].replace(\" \", np.NAN)  # Replace with np.NAN or other value\n",
    "\n",
    "cancer_type_df = cancer_type_df.dropna(subset=['stage_of_cancer_code'])  # Drop rows with NaN in 'stage_of_cancer_code'\n",
    "\n",
    "# Try converting 'stage_of_cancer_code' to numeric, handling potential errors\n",
    "try:\n",
    "      cancer_type_df['stage_of_cancer_code'] = pd.to_numeric(cancer_type_df['stage_of_cancer_code'], errors='raise')\n",
    "except ValueError:\n",
    "      print(\"Error: Some values in 'stage_of_cancer_code' cannot be converted to numeric (after removing empty strings).\")\n",
    "\n",
    "cancer_type_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea464c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cancer_type_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_type_stage_df = cancer_type_df[cancer_type_df['stage_of_cancer_code'] == 1]\n",
    "cancer_type_stage_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fdc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from aif360.sklearn.inprocessing import ExponentiatedGradientReduction\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# separate array into input and output components\n",
    "X = cancer_type_stage_df.drop(['survived_code ', 'stage_of_cancer_code'], axis=1)\n",
    "y = cancer_type_stage_df['survived_code ']\n",
    "\n",
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d40647",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_attr_cols = [colname for colname in X_train \n",
    "                  if \"gender_code\" in colname or \"marital_status_code\" in colname \n",
    "                  or \"race_code\" in colname]\n",
    "prot_attr_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd64903",
   "metadata": {},
   "source": [
    "# 1. Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af133a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_estimator = LogisticRegression(solver='liblinear')\n",
    "lr_exp_grad_red = ExponentiatedGradientReduction(prot_attr=prot_attr_cols, \n",
    "                                              estimator=lr_estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "lr_exp_grad_red.fit(X_train, y_train)\n",
    "lr_egr_acc = lr_exp_grad_red.score(X_test, y_test)\n",
    "print(lr_egr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a8ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fairness\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, y_pred)\n",
    "lr_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5494f14",
   "metadata": {},
   "source": [
    "## 1.1 SHAP For Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap and data visualization tool\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "lr_explainer = shap.Explainer(lr_exp_grad_red.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "lr_shap_values = lr_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(lr_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the explainer for unmitigated model\n",
    "lr_unmitigated_explainer = shap.Explainer(lr.predict, X_train)\n",
    "lr_unmitigated_shap_values = lr_unmitigated_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unmitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(lr_unmitigated_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48dff8",
   "metadata": {},
   "source": [
    "## 1.2 LIME For Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40721bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LimeTabularExplainer module\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get the feature names\n",
    "feature_names = list(X_test.columns)\n",
    "\n",
    "# Fit the Explainer on the training data set using the LimeTabularExplainer\n",
    "lr_explainer = lime.lime_tabular.LimeTabularExplainer(training_data=np.array(X_test),\n",
    "                                 feature_names=X_test.columns,\n",
    "                                 class_names = ['Dead', 'Alive'], \n",
    "                                 mode = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_fn_rf = lambda x: rf.predict_proba(x).astype(float)\n",
    "i = np.random.randint(len(X_test))\n",
    "print(y_test.iloc[i])\n",
    "lr_exp = lr_explainer.explain_instance(X_test.iloc[i], lr_exp_grad_red.predict_proba)\n",
    "lr_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc503aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_exp = lr_explainer.explain_instance(X_test.iloc[i], lr.predict_proba)\n",
    "lr_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da249c94",
   "metadata": {},
   "source": [
    "# 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_estimator = DecisionTreeClassifier()\n",
    "dt_exp_grad_red = ExponentiatedGradientReduction(prot_attr=prot_attr_cols, \n",
    "                                              estimator=dt_estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "dt_exp_grad_red.fit(X_train, y_train)\n",
    "dt_egr_acc = dt_exp_grad_red.score(X_test, y_test)\n",
    "print(dt_egr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fairness\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, y_pred)\n",
    "dt_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6081f7",
   "metadata": {},
   "source": [
    "## 2.1 SHAP For Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e648396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap and data visualization tool\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create the explainer using the subset\n",
    "dt_explainer = shap.Explainer(dt_exp_grad_red.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "dt_shap_values = dt_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aafbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(dt_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee71dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the explainer\n",
    "dt_unmitigated_explainer = shap.Explainer(dt.predict, X_train)\n",
    "dt_unmitigated_shap_values = dt_unmitigated_explainer(X_test)\n",
    "print(\"Unmitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(dt_unmitigated_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4aca7f",
   "metadata": {},
   "source": [
    "## 2.2 LIME For Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad98650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LimeTabularExplainer module\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get the feature names\n",
    "feature_names = list(X_test.columns)\n",
    "\n",
    "# Fit the Explainer on the training data set using the LimeTabularExplainer\n",
    "dt_explainer = lime.lime_tabular.LimeTabularExplainer(training_data=np.array(X_test),\n",
    "                                 feature_names=X_test.columns,\n",
    "                                 class_names = ['Dead', 'Alive'], \n",
    "                                 mode = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbeb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_fn_rf = lambda x: rf.predict_proba(x).astype(float)\n",
    "i = np.random.randint(len(X_test))\n",
    "print(y_test.iloc[i])\n",
    "dt_exp = dt_explainer.explain_instance(X_test.iloc[i], dt_exp_grad_red.predict_proba)\n",
    "dt_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_exp = dt_explainer.explain_instance(X_test.iloc[i], dt.predict_proba)\n",
    "dt_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55a97b",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6823810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_estimator = GaussianNB()\n",
    "nb_exp_grad_red = ExponentiatedGradientReduction(prot_attr=prot_attr_cols, \n",
    "                                              estimator=nb_estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "nb_exp_grad_red.fit(X_train, y_train)\n",
    "nb_egr_acc = nb_exp_grad_red.score(X_test, y_test)\n",
    "print(nb_egr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fairness\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, y_pred)\n",
    "nb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92a71a",
   "metadata": {},
   "source": [
    "## 3.1 SHAP For Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap and data visualization tool\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create the explainer using the subset\n",
    "nb_explainer = shap.Explainer(nb_exp_grad_red.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "nb_shap_values = nb_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(nb_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec0242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the explainer for unmitigated model\n",
    "nb_unimitigated_explainer = shap.Explainer(nb.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "nb_unimitigated_shap_values = nb_unimitigated_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa131235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unmitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(nb_unimitigated_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba62c88",
   "metadata": {},
   "source": [
    "## 3.2 LIME For Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45020f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LimeTabularExplainer module\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get the feature names\n",
    "feature_names = list(X_test.columns)\n",
    "\n",
    "# Fit the Explainer on the training data set using the LimeTabularExplainer\n",
    "nb_explainer = lime.lime_tabular.LimeTabularExplainer(training_data=np.array(X_test),\n",
    "                                 feature_names=X_test.columns,\n",
    "                                 class_names = ['Dead', 'Alive'], \n",
    "                                 mode = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(X_test))\n",
    "print(y_test.iloc[i])\n",
    "nb_exp = nb_explainer.explain_instance(X_test.iloc[i], nb_exp_grad_red.predict_proba)\n",
    "nb_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_exp = nb_explainer.explain_instance(X_test.iloc[i], nb.predict_proba)\n",
    "nb_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d2e56",
   "metadata": {},
   "source": [
    "# 4. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_estimator = AdaBoostClassifier()\n",
    "ada_exp_grad_red = ExponentiatedGradientReduction(prot_attr=prot_attr_cols, \n",
    "                                              estimator=ada_estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "ada_exp_grad_red.fit(X_train, y_train)\n",
    "ada_egr_acc = ada_exp_grad_red.score(X_test, y_test)\n",
    "print(ada_egr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44105e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fairness\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "ada_acc = accuracy_score(y_test, y_pred)\n",
    "ada_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf475e",
   "metadata": {},
   "source": [
    "## 4.1 SHAP For AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap and data visualization tool\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create the explainer using the subset\n",
    "ada_explainer = shap.Explainer(ada_exp_grad_red.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "ada_shap_values = ada_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee27711",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(ada_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the explainer for unmitigated model\n",
    "ada_unmitigated_explainer = shap.Explainer(ada.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "ada_unmitigated_shap_values = ada_unmitigated_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e00069",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unmitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(ada_unmitigated_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866acbb2",
   "metadata": {},
   "source": [
    "## 4.2 LIME For AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LimeTabularExplainer module\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get the feature names\n",
    "feature_names = list(X_test.columns)\n",
    "\n",
    "# Fit the Explainer on the training data set using the LimeTabularExplainer\n",
    "ada_explainer = lime.lime_tabular.LimeTabularExplainer(training_data=np.array(X_test),\n",
    "                                 feature_names=X_test.columns,\n",
    "                                 class_names = ['Dead', 'Alive'], \n",
    "                                 mode = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(X_test))\n",
    "print(y_test.iloc[i])\n",
    "ada_exp = ada_explainer.explain_instance(X_test.iloc[i], ada_exp_grad_red.predict_proba)\n",
    "ada_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_exp = ada_explainer.explain_instance(X_test.iloc[i], ada.predict_proba)\n",
    "ada_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2222430",
   "metadata": {},
   "source": [
    "# 5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9760a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_estimator = XGBClassifier()\n",
    "xgb_exp_grad_red = ExponentiatedGradientReduction(prot_attr=prot_attr_cols, \n",
    "                                              estimator=xgb_estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "xgb_exp_grad_red.fit(X_train, y_train)\n",
    "xgb_egr_acc = xgb_exp_grad_red.score(X_test, y_test)\n",
    "print(xgb_egr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ebe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fairness\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, y_pred)\n",
    "xgb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3551ee0",
   "metadata": {},
   "source": [
    "## 5.1 SHAP For XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap and data visualization tool\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create the explainer using the subset\n",
    "xgb_explainer = shap.Explainer(xgb_exp_grad_red.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "xgb_shap_values = xgb_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ae73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(xgb_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the explainer for unmitigated model\n",
    "xgb_unmitigated_explainer = shap.Explainer(xgb.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "xgb_unmitigated_shap_values = xgb_unmitigated_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unmitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(xgb_unmitigated_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c2a60",
   "metadata": {},
   "source": [
    "## 5.2 LIME For XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LimeTabularExplainer module\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get the feature names\n",
    "feature_names = list(X_test.columns)\n",
    "\n",
    "# Fit the Explainer on the training data set using the LimeTabularExplainer\n",
    "xgb_explainer = lime.lime_tabular.LimeTabularExplainer(training_data=np.array(X_test),\n",
    "                                 feature_names=X_test.columns,\n",
    "                                 class_names = ['Dead', 'Alive'], \n",
    "                                 mode = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(X_test))\n",
    "print(y_test.iloc[i])\n",
    "xgb_exp = xgb_explainer.explain_instance(X_test.iloc[i], xgb_exp_grad_red.predict_proba)\n",
    "xgb_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_exp = xgb_explainer.explain_instance(X_test.iloc[i], xgb.predict_proba)\n",
    "xgb_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151a986",
   "metadata": {},
   "source": [
    "# 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_estimator = RandomForestClassifier()\n",
    "rf_exp_grad_red = ExponentiatedGradientReduction(prot_attr=prot_attr_cols, \n",
    "                                              estimator=rf_estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "rf_exp_grad_red.fit(X_train, y_train)\n",
    "rf_egr_acc = rf_exp_grad_red.score(X_test, y_test)\n",
    "print(rf_egr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651230eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, y_pred)\n",
    "rf_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10818b00",
   "metadata": {},
   "source": [
    "## 6.1 SHAP for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff38b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap and data visualization tool\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create the explainer using the subset\n",
    "rf_explainer = shap.Explainer(rf_exp_grad_red.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "rf_shap_values = rf_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(rf_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11afcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the explainer for unmitigated model\n",
    "rf_unmitigated_explainer = shap.Explainer(rf.predict, X_train)\n",
    "\n",
    "# Calculate SHAP values for the subset\n",
    "rf_unmitigated_shap_values = rf_unmitigated_explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cabf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unmitigated Variable Importance Plot - Global Interpretation\")\n",
    "figure = plt.figure()\n",
    "shap.summary_plot(rf_unmitigated_shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e9c86",
   "metadata": {},
   "source": [
    "## 6.2 LIME for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b1f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LimeTabularExplainer module\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get the feature names\n",
    "feature_names = list(X_test.columns)\n",
    "\n",
    "# Fit the Explainer on the training data set using the LimeTabularExplainer\n",
    "rf_explainer = lime.lime_tabular.LimeTabularExplainer(training_data=np.array(X_test),\n",
    "                                 feature_names=X_test.columns,\n",
    "                                 class_names = ['Dead', 'Alive'], \n",
    "                                 mode = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(X_test))\n",
    "print(y_test.iloc[i])\n",
    "rf_exp = rf_explainer.explain_instance(X_test.iloc[i], rf_exp_grad_red.predict_proba)\n",
    "rf_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_exp = rf_explainer.explain_instance(X_test.iloc[i], rf.predict_proba)\n",
    "rf_exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83eeaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
